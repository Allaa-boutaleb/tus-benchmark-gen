{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "db7538d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (2.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (8.1.4)\n",
      "Requirement already satisfied: cloudpickle<3 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (2.2.1)\n",
      "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (0.17.7)\n",
      "Requirement already satisfied: entrypoints<1 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (0.4)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (3.1.32)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (6.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (3.20.3)\n",
      "Requirement already satisfied: pytz<2024 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (2023.3)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (2.28.2)\n",
      "Requirement already satisfied: packaging<24 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (23.1)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (6.0.1)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (0.4.4)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (1.11.1)\n",
      "Requirement already satisfied: docker<7,>=4.0.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (6.1.3)\n",
      "Requirement already satisfied: Flask<3 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (2.3.2)\n",
      "Requirement already satisfied: numpy<2 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (1.24.4)\n",
      "Requirement already satisfied: scipy<2 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (1.10.1)\n",
      "Requirement already satisfied: pandas<3 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (2.0.3)\n",
      "Requirement already satisfied: querystring-parser<2 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (2.0.18)\n",
      "Requirement already satisfied: scikit-learn<2 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (1.3.0)\n",
      "Requirement already satisfied: pyarrow<13,>=4.0.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (12.0.1)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: matplotlib<4 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (3.7.2)\n",
      "Requirement already satisfied: gunicorn<21 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (20.1.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: Mako in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from alembic!=1.10.0,<2->mlflow) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from alembic!=1.10.0,<2->mlflow) (4.5.0)\n",
      "Requirement already satisfied: importlib-resources in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from alembic!=1.10.0,<2->mlflow) (6.0.0)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.7 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.26.16)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from docker<7,>=4.0.0->mlflow) (1.6.1)\n",
      "Requirement already satisfied: Werkzeug>=2.3.3 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from Flask<3->mlflow) (2.3.6)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from Flask<3->mlflow) (2.1.2)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from Flask<3->mlflow) (1.6.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.10)\n",
      "Requirement already satisfied: setuptools>=3.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from gunicorn<21->mlflow) (67.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from matplotlib<4->mlflow) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from matplotlib<4->mlflow) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from matplotlib<4->mlflow) (9.5.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from pandas<3->mlflow) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow) (2023.5.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from scikit-learn<2->mlflow) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from scikit-learn<2->mlflow) (3.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: greenlet!=0.4.17 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /disk/u/koyena/miniconda3/envs/benchmarkgen/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4916f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pickle5 as p\n",
    "import pandas as pd\n",
    "from matplotlib import *\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8e17562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDictionaryFromPickleFile(dictionaryPath):\n",
    "    ''' Load the pickle file as a dictionary\n",
    "    Args:\n",
    "        dictionaryPath: path to the pickle file\n",
    "    Return: dictionary from the pickle file\n",
    "    '''\n",
    "    filePointer=open(dictionaryPath, 'rb')\n",
    "    dictionary = p.load(filePointer)\n",
    "    filePointer.close()\n",
    "    return dictionary\n",
    "\n",
    "def loadDictionaryFromPickleFileList(dictionaryPath):\n",
    "    ''' Load the pickle file as a dictionary\n",
    "    Args:\n",
    "        dictionaryPath: path to the pickle file\n",
    "    Return: dictionary from the pickle file\n",
    "    '''\n",
    "    filePointer=open(dictionaryPath, 'rb')\n",
    "    dictionary = p.load(filePointer)\n",
    "    filePointer.close()\n",
    "    actual_dict = {}\n",
    "    for curr_dict in dictionary:\n",
    "        actual_dict[curr_dict['query_table']] = curr_dict['result_set']\n",
    "    return actual_dict\n",
    "\n",
    "def saveDictionaryAsPickleFile(dictionary, dictionaryPath):\n",
    "    ''' Save dictionary as a pickle file\n",
    "    Args:\n",
    "        dictionary to be saved\n",
    "        dictionaryPath: filepath to which the dictionary will be saved\n",
    "    '''\n",
    "    filePointer=open(dictionaryPath, 'wb')\n",
    "    pickle.dump(dictionary,filePointer, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    filePointer.close()\n",
    "\n",
    "\n",
    "def calcMetrics(max_k, k_range, gtPath=None, resPath=None, record=True):\n",
    "    ''' Calculate and log the performance metrics: MAP, Precision@k, Recall@k\n",
    "    Args:\n",
    "        max_k: the maximum K value (e.g. for SANTOS benchmark, max_k = 10. For TUS benchmark, max_k = 60)\n",
    "        k_range: step size for the K's up to max_k\n",
    "        gtPath: file path to the groundtruth\n",
    "        resPath: file path to the raw results from the model\n",
    "        record (boolean): to log in MLFlow or not\n",
    "    Return: MAP, P@K, R@K\n",
    "    '''\n",
    "    groundtruth = loadDictionaryFromPickleFile(gtPath)\n",
    "    resultFile = loadDictionaryFromPickleFile(resPath)\n",
    "    fullresultFile = resultFile\n",
    "    if type(resultFile) == list:\n",
    "        resultFile = loadDictionaryFromPickleFileList(resPath)\n",
    "    # =============================================================================\n",
    "    # Precision and recall\n",
    "    # =============================================================================\n",
    "    precision_array = []\n",
    "    recall_array = []\n",
    "    final_results = []\n",
    "    for k in range(1, max_k+1):\n",
    "        true_positive = 0\n",
    "        false_positive = 0\n",
    "        false_negative = 0\n",
    "        rec = 0\n",
    "        ideal_recall = []\n",
    "        index_counter = 0\n",
    "        for table in resultFile:\n",
    "            # t28 tables have less than 60 results. So, skipping them in the analysis.\n",
    "            if table.split(\"____\",1)[0] != \"t_28dc8f7610402ea7\": \n",
    "                if table in groundtruth:\n",
    "                    groundtruth_set = set(groundtruth[table])\n",
    "                    groundtruth_set = {x.split(\".\")[0] for x in groundtruth_set}\n",
    "                    result_set = resultFile[table][:k]\n",
    "                    result_set = [x.split(\".\")[0] for x in result_set]\n",
    "                    # find_intersection = true positives\n",
    "                    #if len(resultFile[table]) > 10 and k==10:\n",
    "                    #    print(\"LEN RESULT SET\", len(resultFile[table]))\n",
    "                    #    print(fullresultFile[index_counter]['confidence_set'])\n",
    "                    find_intersection = set(result_set).intersection(groundtruth_set)\n",
    "                    curr_result_dict = {}\n",
    "                    curr_result_dict[\"groundtruth_set\"] = groundtruth_set\n",
    "                    curr_result_dict[\"result_set\"] = result_set\n",
    "                    curr_result_dict[\"intersection\"] = find_intersection\n",
    "                    final_results.append(curr_result_dict)\n",
    "                    tp = len(find_intersection)\n",
    "                    fp = k - tp\n",
    "                    fn = len(groundtruth_set) - tp\n",
    "                    if len(groundtruth_set)>=k: \n",
    "                        true_positive += tp\n",
    "                        false_positive += fp\n",
    "                        false_negative += fn\n",
    "                    rec += tp / (tp+fn)\n",
    "                    ideal_recall.append(k/len(groundtruth[table]))\n",
    "            index_counter += 1\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "        recall = rec/len(resultFile)\n",
    "        precision_array.append(precision)\n",
    "        recall_array.append(recall)\n",
    "#         if k % 10 == 0:\n",
    "        print(k, \"IDEAL RECALL:\", sum(ideal_recall)/len(ideal_recall))\n",
    "    used_k = [k_range]\n",
    "    if max_k >k_range:\n",
    "        for i in range(k_range * 2, max_k+1, k_range):\n",
    "            used_k.append(i)\n",
    "    print(\"--------------------------\")\n",
    "    for k in used_k:\n",
    "        print(\"Precision at k = \",k,\"=\", precision_array[k-1])\n",
    "        print(\"Recall at k = \",k,\"=\", recall_array[k-1])\n",
    "        print(\"--------------------------\")\n",
    "    \n",
    "    map_sum = 0\n",
    "    for k in range(0, max_k):\n",
    "        map_sum += precision_array[k]\n",
    "    mean_avg_pr = map_sum/max_k\n",
    "    print(\"The mean average precision is:\", mean_avg_pr)\n",
    "    output_result_csv_file = \"curr_run_results.csv\"\n",
    "    pd.DataFrame(final_results).to_csv(output_result_csv_file)\n",
    "\n",
    "    # logging to mlflow\n",
    "    if record: # if the user would like to log to MLFlow\n",
    "        mlflow.log_metric(\"mean_avg_precision\", mean_avg_pr)\n",
    "        mlflow.log_metric(\"prec_k\", precision_array[max_k-1])\n",
    "        mlflow.log_metric(\"recall_k\", recall_array[max_k-1])\n",
    "\n",
    "    return mean_avg_pr, precision_array[max_k-1], recall_array[max_k-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d798c1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 IDEAL RECALL: 0.09999999999999996\n",
      "2 IDEAL RECALL: 0.19999999999999993\n",
      "3 IDEAL RECALL: 0.30000000000000027\n",
      "4 IDEAL RECALL: 0.39999999999999986\n",
      "5 IDEAL RECALL: 0.5\n",
      "6 IDEAL RECALL: 0.6000000000000005\n",
      "7 IDEAL RECALL: 0.6999999999999998\n",
      "8 IDEAL RECALL: 0.7999999999999997\n",
      "9 IDEAL RECALL: 0.8999999999999991\n",
      "10 IDEAL RECALL: 1.0\n",
      "--------------------------\n",
      "Precision at k =  1 = 0.74\n",
      "Recall at k =  1 = 0.07400000000000004\n",
      "--------------------------\n",
      "Precision at k =  2 = 0.65\n",
      "Recall at k =  2 = 0.13000000000000003\n",
      "--------------------------\n",
      "Precision at k =  3 = 0.6066666666666667\n",
      "Recall at k =  3 = 0.18199999999999997\n",
      "--------------------------\n",
      "Precision at k =  4 = 0.55\n",
      "Recall at k =  4 = 0.21999999999999997\n",
      "--------------------------\n",
      "Precision at k =  5 = 0.544\n",
      "Recall at k =  5 = 0.2720000000000001\n",
      "--------------------------\n",
      "Precision at k =  6 = 0.5333333333333333\n",
      "Recall at k =  6 = 0.32000000000000006\n",
      "--------------------------\n",
      "Precision at k =  7 = 0.5085714285714286\n",
      "Recall at k =  7 = 0.3560000000000001\n",
      "--------------------------\n",
      "Precision at k =  8 = 0.48\n",
      "Recall at k =  8 = 0.38400000000000006\n",
      "--------------------------\n",
      "Precision at k =  9 = 0.4777777777777778\n",
      "Recall at k =  9 = 0.42999999999999994\n",
      "--------------------------\n",
      "Precision at k =  10 = 0.454\n",
      "Recall at k =  10 = 0.45399999999999996\n",
      "--------------------------\n",
      "The mean average precision is: 0.5544349206349206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5544349206349206, 0.454, 0.45399999999999996)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcMetrics(max_k=10, k_range=1, \n",
    "            gtPath='../data/ugen_v1/santosUnionBenchmark.pickle', \n",
    "            resPath='../starmie-llm-results/vicuna7b_ugen_v1_sparse_20_icl-1_result.pickle', record=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7990198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = loadDictionaryFromPickleFile('data/d3l_santos/santos_benchmark_result_by_d3l.pickle')\n",
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f7d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datalake_and_query_folders(in_dir, out_dir, gtfile, query_col=\"query_table\", datalake_col=\"data_lake_table\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    query_folder = os.path.join(out_dir, \"query\")\n",
    "    datalake_folder = os.path.join(out_dir, \"datalake\")\n",
    "    os.makedirs(query_folder, exist_ok=True)\n",
    "    os.makedirs(datalake_folder, exist_ok=True)\n",
    "    gt_df = pd.read_csv(gtfile)\n",
    "    counter = 0\n",
    "    for _, row in gt_df.iterrows():\n",
    "        query_table = row[query_col]\n",
    "        datalake_table = row[datalake_col]\n",
    "        qt_file = os.path.join(query_folder, query_table)\n",
    "        dlt_file = os.path.join(datalake_folder, datalake_table)\n",
    "        if not os.path.isfile(qt_file):\n",
    "            counter += 1\n",
    "            in_file = os.path.join(in_dir, query_table)\n",
    "            shutil.copy(in_file, query_folder)\n",
    "#         if not os.path.isfile(dlt_file):\n",
    "#             in_file = os.path.join(in_dir, datalake_table)\n",
    "#             shutil.copy(in_file, datalake_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae18c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"data/table-union-search-benchmark/small/santos-query\"\n",
    "out_dir = \"data/table-union-search-benchmark/small\"\n",
    "gtfile = \"TUS_benchmark_relabeled_groundtruth.csv\"\n",
    "create_datalake_and_query_folders(in_dir, out_dir, gtfile, query_col=\"query_table\", datalake_col=\"data_lake_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_pickle(gtfile, out_pickle, query_col=\"query_table\", datalake_col=\"data_lake_table\", label=\"unionable\"):\n",
    "    query_datalake_dict = {}\n",
    "    gt_df = pd.read_csv(gtfile)\n",
    "    for _, row in gt_df.iterrows():\n",
    "        query_table = row[query_col]\n",
    "        datalake_table = row[datalake_col]\n",
    "        is_unionable = row[label]\n",
    "        if (is_unionable == 1):\n",
    "            if query_table not in query_datalake_dict:\n",
    "                query_datalake_dict[query_table] = [datalake_table]\n",
    "            else:\n",
    "                curr_tables = set(query_datalake_dict[query_table])\n",
    "                curr_tables.add(datalake_table)\n",
    "                query_datalake_dict[query_table] = list(curr_tables)\n",
    "    for key, value in query_datalake_dict.items():\n",
    "        print(len(value))\n",
    "        print(key, value)\n",
    "    with open(out_pickle, 'wb') as handle:\n",
    "        pickle.dump(query_datalake_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
